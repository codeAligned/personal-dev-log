# Key-Value Cache for Search Engine
#
# Design a key-value cache to save the results of the most recent
# web server queries, including a snippet about the search results
# itself.

# In case youâ€™re not already familiar, a cache system is a widely
# adopted technique that is used in nearly every application today
# and applies to every layer of the technology stack. A cache
# system stores commonly used resources, for example in-memory,
# and the next time a request is made for the same resource,
# the system can return it immediately.

#========================================================
Part 1: User Cases and Constraints

1. user cases
  - user makes a cache hit with search query
  - user makes a cache miss with search query

2 constraints
  - traffic is not evenly distributed
  - cache needs to return results at a fast rate
  - cache resource is limited (stored in memory)
    - need to keep popular queries and eliminate non-popular ones
  - 10 million users / month
  - 10 billion queries / month
    - needs to store many queries inside the query

3. basic calculation behind the system to be built
    - query --> 50 bytes
    - snippets --> 2~3 kilobytes
    - total: ~2 to 3 kilobytes
    - 30 trillion bytes --> 30 TB of data /month
    - 4000 queries per second


# ==============================================
Part 2: High Level Design

4. basic design
    - see screen shot "key_value_cache_part2.png"

# ==============================================
Part 3: Designing Core Concepts

  Requirements
    - reousrce for memcache is limited
    - capable of handing >4000 requests / second
    - return results at a fast rate

  Use LRU (Last renctly used) cache

    input: string
    output: Node


  class cache:
    def __init__():
      self.max = 0
      self.linked_list = LinkedList()

    - get
      1. check to see if query exists in cache

    def get(self, query):
        temp = self.linked_list.head

        while temp.next != None:

          if query == temp.next.query:
            output = temp.next
            self.linked_list.bring_to_front(output)
            return output

          temp = temp.next

        reutrn None

      2. if query exists in cache, return result, and bring the node to the front
      3. if query doesn't exist, return None


    - set
    def set(self,query,results):
        1. store query and result in node
        temp_node = self.Node(query,result)


        2. if size of linked list == MAX, then remove last and append node to top
        if self.linked_list.size == self.Max:
          self.linked_list_remove_last()

        self.linked_list_add_to_front(node)

    3. if size of linked list < MAX, append node to top

# ==============================================
Ppar 4: Scaling the Design

